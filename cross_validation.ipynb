{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from tensorflow.keras.metrics import MeanSquaredError, RootMeanSquaredError, MeanAbsoluteError\n",
    "from src.LongShortTermMemory import LSTMModel\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from src.StockDataProcessor import StockDataProcessor\n",
    "from src.LongShortTermMemory import LSTMModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossValidator:\n",
    "    \"\"\"\n",
    "    Performs time series cross-validation for LSTM models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_splits=5):\n",
    "        \"\"\"\n",
    "        Initializes the cross-validator.\n",
    "\n",
    "        Args:\n",
    "            n_splits: The number of splits for cross-validation.\n",
    "        \"\"\"\n",
    "        self.n_splits = n_splits\n",
    "        self.tscv = TimeSeriesSplit(n_splits=self.n_splits)\n",
    "\n",
    "    def cross_val_score(self, model_creator, data, time_steps, epochs=50, batch_size=32):\n",
    "        \"\"\"\n",
    "        Performs cross-validation and returns the evaluation scores.\n",
    "\n",
    "        Args:\n",
    "            model_creator: A function that returns a compiled Keras model.\n",
    "            data: The raw stock price data (Pandas DataFrame or Series).\n",
    "            time_steps: The number of time steps for creating sequences.\n",
    "            epochs: The number of epochs for training.\n",
    "            batch_size: The batch size for training.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of dictionaries containing evaluation metrics for each fold.\n",
    "        \"\"\"\n",
    "        all_scores = []\n",
    "\n",
    "        for fold, (train_index, test_index) in enumerate(self.tscv.split(data)):\n",
    "            print(f\"Fold: {fold + 1}\")\n",
    "\n",
    "            # --- Create Sequences for This Fold --- \n",
    "            train_data = data.iloc[train_index]\n",
    "            test_data = data.iloc[test_index]\n",
    "\n",
    "            # Assuming data['Close'] has your closing prices (adjust if needed)\n",
    "            scaler = MinMaxScaler()  # Create a new scaler for each fold\n",
    "            train_data['Close'] = scaler.fit_transform(train_data[['Close']])\n",
    "            test_data['Close'] = scaler.transform(test_data[['Close']]) # Assuming using only 'Close' - need to align the 'Close' column with the scaling process\n",
    "\n",
    "            X_train, y_train = self._create_sequences(train_data['Close'], time_steps)\n",
    "            X_test, y_test = self._create_sequences(test_data['Close'], time_steps)\n",
    "\n",
    "            # --- Model Training and Evaluation ---\n",
    "            model = model_creator()\n",
    "            model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "            scores = self.evaluate_model(model, X_test, y_test)\n",
    "            all_scores.append(scores)\n",
    "\n",
    "        return all_scores\n",
    "\n",
    "\n",
    "    def _create_sequences(self, data, time_steps):\n",
    "        \"\"\"\n",
    "        Helper function to create time series sequences.\n",
    "        \"\"\"\n",
    "        X, y = [], []\n",
    "        for i in range(time_steps, len(data)):\n",
    "            X.append(data[i-time_steps:i])\n",
    "            y.append(data[i])\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "    def evaluate_model(self, model, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluates the model and returns a dictionary of metrics.\n",
    "        \"\"\"\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        mse = MeanSquaredError()(y_test, y_pred).numpy()\n",
    "        rmse = RootMeanSquaredError()(y_test, y_pred).numpy() # np.sqrt(mse)  \n",
    "        mae = MeanAbsoluteError()(y_test, y_pred).numpy()\n",
    "\n",
    "        return {'mse': mse, 'rmse': rmse, 'mae': mae}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 10\n",
    "TIME_STEPS = 60\n",
    "\n",
    "FOLDER_PREFIX = \"data/min/\"\n",
    "STOCK_START_DATE = pd.to_datetime(\"2017-06-07 15:59:00\")\n",
    "STOCK_VALIDATION_DATE = pd.to_datetime(\"2024-06-09 09:30:00\")\n",
    "STOCK_END_DATE = pd.to_datetime(\"2024-06-12 15:59:00\")\n",
    "TOKEN = \"GOOG\"\n",
    "RUN_FOLDER = f\"{FOLDER_PREFIX}{TOKEN}/\"\n",
    "WORK_DIR = os.path.join(os.getcwd(), RUN_FOLDER)\n",
    "CSV_FILE = f\"{WORK_DIR}data.csv\"\n",
    "\n",
    "PROJECT_FOLDER = os.path.join(os.getcwd(), RUN_FOLDER)\n",
    "if not os.path.exists(PROJECT_FOLDER):\n",
    "    os.makedirs(PROJECT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test), (training_data, test_data) = StockDataProcessor.load_csv_transform_to_numpy(TIME_STEPS, CSV_FILE, STOCK_VALIDATION_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CrossValidator instance\n",
    "cross_validator = CrossValidator(n_splits=5)\n",
    "\n",
    "# Perform cross-validation (pass raw data and time_steps)\n",
    "all_scores = cross_validator.cross_val_score(\n",
    "    LSTMModel.create, \n",
    "    x_train,\n",
    "    time_steps=TIME_STEPS,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "# Print the results for each fold\n",
    "for fold, scores in enumerate(all_scores):\n",
    "    print(f\"Fold {fold + 1}: MSE={scores['mse']:.4f}, RMSE={scores['rmse']:.4f}, MAE={scores['mae']:.4f}\")\n",
    "\n",
    "# Calculate and print the average scores across all folds\n",
    "average_scores = {metric: np.mean([fold_scores[metric] for fold_scores in all_scores]) for metric in all_scores[0]}\n",
    "print(f\"Average: MSE={average_scores['mse']:.4f}, RMSE={average_scores['rmse']:.4f}, MAE={average_scores['mae']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
