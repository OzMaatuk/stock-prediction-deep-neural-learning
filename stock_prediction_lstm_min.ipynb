{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "057ed8f6",
   "metadata": {},
   "source": [
    "## LSTM Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a4edc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "from src.stock_prediction_class import StockClass\n",
    "from src.stock_prediction_numpy import DataClass\n",
    "from src.stock_prediction_deep_learning import train_LSTM_network\n",
    "\n",
    "# Suppress TensorFlow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or '3' to suppress all messages\n",
    "\n",
    "# Suppress other warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"tensorflow\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfc2ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import secrets\n",
    "# TOKEN = STOCK_TICKER + '_' + TODAY_RUN + '_' + secrets.token_hex(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e8a3a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "STOCK_TICKER = \"GOOG\"\n",
    "STOCK_START_DATE = pd.to_datetime(\"2024-05-24 09:30:00\")\n",
    "STOCK_VALIDATION_DATE = pd.to_datetime(\"2024-05-29 10:52:00\")\n",
    "STOCK_END_DATE = pd.to_datetime(\"2024-05-30 15:59:00\")\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 10\n",
    "TIME_STEPS = 60\n",
    "TODAY_RUN = datetime.today().strftime(\"%Y%m%d\")\n",
    "TOKEN = \"GOOG\"\n",
    "FOLDER_PREFIX = \"data/min/\"\n",
    "RUN_FOLDER = f\"{FOLDER_PREFIX}{TOKEN}/\"\n",
    "WORK_DIR = os.path.join(os.getcwd(), RUN_FOLDER)\n",
    "CSV_FILE = f\"{WORK_DIR}data.csv\"\n",
    "\n",
    "print('Ticker: ' + STOCK_TICKER)\n",
    "print('Start Date: ' + STOCK_START_DATE.strftime(\"%Y-%m-%d\"))\n",
    "print('Validation Date: ' + STOCK_VALIDATION_DATE.strftime(\"%Y-%m-%d\"))\n",
    "print('Test Run Folder: ' + RUN_FOLDER)\n",
    "\n",
    "PROJECT_FOLDER = os.path.join(os.getcwd(), RUN_FOLDER)\n",
    "if not os.path.exists(PROJECT_FOLDER):\n",
    "    os.makedirs(PROJECT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3068309",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_prediction = StockClass(STOCK_TICKER, \n",
    "                                   STOCK_START_DATE,\n",
    "                                   STOCK_END_DATE,\n",
    "                                   STOCK_VALIDATION_DATE, \n",
    "                                   PROJECT_FOLDER, \n",
    "                                   EPOCHS,\n",
    "                                   TIME_STEPS,\n",
    "                                   TOKEN,\n",
    "                                   BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66039f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "stock_data = DataClass()\n",
    "# (x_train, y_train), (x_test, y_test), (training_data, test_data) = data.download_transform_to_numpy(\n",
    "    # stock.ticker, \n",
    "    # stock.time_steps, \n",
    "    # stock.project_folder,\n",
    "    # stock.start_date,\n",
    "    # stock.end_date,\n",
    "    # stock.validation_date)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test), (training_data, test_data) = stock_data.load_csv_transform_to_numpy(TIME_STEPS, CSV_FILE, STOCK_VALIDATION_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efab5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Deep Learning model\n",
    "train_LSTM_network(stock_data, stock_prediction, x_train, y_train, x_test, y_test, training_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e586ea",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc642506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_data(stock_data, start_date, end_date, latest_close_price, work_dir):\n",
    "    \n",
    "    x_test, y_test, test_data = stock_data.generate_future_data(TIME_STEPS, start_date, end_date, latest_close_price)\n",
    "\n",
    "    # Check if the future data is not empty\n",
    "    if x_test.shape[0] > 0:\n",
    "        # load the weights from our best model\n",
    "        model = tf.keras.models.load_model(os.path.join(work_dir, 'model_weights.keras'))\n",
    "        model.summary()\n",
    "\n",
    "        # perform a prediction\n",
    "        test_predictions_baseline = model.predict(x_test)\n",
    "        test_predictions_baseline = stock_data.min_max.inverse_transform(test_predictions_baseline)\n",
    "        test_predictions_baseline = pd.DataFrame(test_predictions_baseline, columns=['Predicted_Price'])\n",
    "\n",
    "        # Combine the predicted values with dates from the test data\n",
    "        predicted_dates = pd.date_range(start=test_data.index[0], periods=len(test_predictions_baseline), freq=\"1min\")\n",
    "        test_predictions_baseline['Datetime'] = predicted_dates\n",
    "        \n",
    "        # Reset the index for proper concatenation\n",
    "        test_data.reset_index(inplace=True)\n",
    "        \n",
    "        # Concatenate the test_data and predicted data\n",
    "        combined_data = pd.concat([test_data, test_predictions_baseline], ignore_index=True)\n",
    "        \n",
    "        # Plotting predictions\n",
    "        plt.figure(figsize=(14, 5))\n",
    "        plt.plot(combined_data['Datetime'], combined_data.Close, color='green', label='Simulated [' + STOCK_TICKER + '] price')\n",
    "        plt.plot(combined_data['Datetime'], combined_data['Predicted_Price'], color='red', label='Predicted [' + STOCK_TICKER + '] price')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Price [USD]')\n",
    "        plt.legend()\n",
    "        plt.title('Simulated vs Predicted Prices')\n",
    "        plt.savefig(os.path.join(work_dir, 'future_comparison.png'))\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Error: Future data is empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b787fe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(CSV_FILE)\n",
    "\n",
    "latest_close_price = data['Close'].iloc[-1]\n",
    "latest_date = data['Datetime'].iloc[-1]\n",
    "\n",
    "print(f\"{latest_close_price}: latest_close_price\")\n",
    "print(f\"{latest_date}: latest_date\")\n",
    "\n",
    "start_date = pd.to_datetime(latest_date) + timedelta(1)\n",
    "end_date = pd.to_datetime(start_date) + timedelta(1)\n",
    "\n",
    "print(f\"{start_date}: start_date\")\n",
    "print(f\"{end_date}: end_date\")\n",
    "\n",
    "infer_data(stock_data, start_date, end_date, latest_close_price, WORK_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029af865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
