{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "057ed8f6",
   "metadata": {},
   "source": [
    "## LSTM Network - Prediction (model training)\n",
    "\n",
    "The example below will build the LSTM model on the FTSE 100 up to today (2024-01-03) and split the training/validation. Then the prediction module will look ahead 300 days and try to make a  prediction based on a random generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53a4edc8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'stock_prediction_class'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstock_prediction_plotter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Plotter\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstock_prediction_readme_generator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReadmeGenerator\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstock_prediction_deep_learning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_LSTM_network\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Suppress TensorFlow warnings\u001b[39;00m\n\u001b[1;32m     30\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTF_CPP_MIN_LOG_LEVEL\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# or '3' to suppress all messages\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/stock-prediction-deep-neural-learning/src/stock_prediction_deep_learning.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01margparse\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstock_prediction_class\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StockPrediction\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstock_prediction_lstm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LongShortTermMemory\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstock_prediction_numpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StockData\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'stock_prediction_class'"
     ]
    }
   ],
   "source": [
    "# Copyright 2020-2024 Jordi Corbilla. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "import os\n",
    "# os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "import warnings\n",
    "import secrets\n",
    "import pandas as pd\n",
    "\n",
    "from src.stock_prediction_class import StockPrediction\n",
    "from src.stock_prediction_lstm import LongShortTermMemory\n",
    "from src.stock_prediction_numpy import StockData\n",
    "from src.stock_prediction_plotter import Plotter\n",
    "from src.stock_prediction_readme_generator import ReadmeGenerator\n",
    "from src.stock_prediction_deep_learning import train_LSTM_network\n",
    "\n",
    "# Suppress TensorFlow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or '3' to suppress all messages\n",
    "\n",
    "# Suppress other warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"tensorflow\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "# os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e8a3a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "FOLDER_PREFIX = \"./data/\"\n",
    "STOCK_TICKER = \"GOOG\"\n",
    "STOCK_START_DATE = pd.to_datetime(\"2020-05-01\")\n",
    "STOCK_VALIDATION_DATE = pd.to_datetime(\"2021-05-01\")\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 10\n",
    "TIME_STEPS = 3\n",
    "TODAY_RUN = datetime.today().strftime(\"%Y%m%d\")\n",
    "TOKEN = STOCK_TICKER + '_' + TODAY_RUN + '_' + secrets.token_hex(16)\n",
    "GITHUB_URL = \"https://github.com/OzMaatuk/stock-prediction-deep-neural-learning\"\n",
    "RUN_FOLDER = f\"{FOLDER_PREFIX}{TOKEN}/\"\n",
    "print('Ticker: ' + STOCK_TICKER)\n",
    "print('Start Date: ' + STOCK_START_DATE.strftime(\"%Y-%m-%d\"))\n",
    "print('Validation Date: ' + STOCK_START_DATE.strftime(\"%Y-%m-%d\"))\n",
    "print('Test Run Folder: ' + TOKEN)\n",
    "# create project run folder\n",
    "PROJECT_FOLDER = os.path.join(os.getcwd(), RUN_FOLDER)\n",
    "if not os.path.exists(PROJECT_FOLDER):\n",
    "    os.makedirs(PROJECT_FOLDER)\n",
    "\n",
    "stock_prediction = StockPrediction(STOCK_TICKER, \n",
    "                                   STOCK_START_DATE, \n",
    "                                   STOCK_VALIDATION_DATE, \n",
    "                                   PROJECT_FOLDER, \n",
    "                                   GITHUB_URL,\n",
    "                                   EPOCHS,\n",
    "                                   TIME_STEPS,\n",
    "                                   TOKEN,\n",
    "                                   BATCH_SIZE)\n",
    "# Execute Deep Learning model\n",
    "train_LSTM_network(stock_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e586ea",
   "metadata": {},
   "source": [
    "## Infer the Future Data (Predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc642506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_data():\n",
    "    print(tf.version.VERSION)\n",
    "    inference_folder = os.path.join(os.getcwd(), RUN_FOLDER)\n",
    "    stock = StockPrediction(STOCK_TICKER, STOCK_START_DATE, STOCK_VALIDATION_DATE, inference_folder, GITHUB_URL, EPOCHS, TIME_STEPS, TOKEN, BATCH_SIZE)\n",
    "\n",
    "    data = StockData(stock)\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test), (training_data, test_data) = data.download_transform_to_numpy(TIME_STEPS, inference_folder)\n",
    "    # csv_file = \"GOOG_20240528_fb072a8138b95ea29aa62ab05c346aee/downloaded_data_GOOG.csv\"\n",
    "    # (x_train, y_train), (x_test, y_test), (training_data, test_data) = data.load_data_csv(TIME_STEPS, csv_file)\n",
    "    min_max = data.get_min_max()\n",
    "\n",
    "    # load future data\n",
    "    print('Latest Stock Price')\n",
    "    latest_close_price = test_data.Close.iloc[-1]\n",
    "    latest_date = test_data[-1:]['Close'].idxmin()\n",
    "    print(latest_close_price)\n",
    "    print('Latest Date')\n",
    "    print(latest_date)\n",
    "\n",
    "    tomorrow_date = latest_date + timedelta(1)\n",
    "    # Specify the next 300 days\n",
    "    next_year = latest_date + timedelta(TIME_STEPS * 100)\n",
    "\n",
    "    print('Future Date')\n",
    "    print(tomorrow_date)\n",
    "\n",
    "    print('Future Timespan Date')\n",
    "    print(next_year)\n",
    "\n",
    "    x_test, y_test, test_data = data.generate_future_data(TIME_STEPS, min_max, tomorrow_date, next_year, latest_close_price)\n",
    "\n",
    "    # Check if the future data is not empty\n",
    "    if x_test.shape[0] > 0:\n",
    "        # load the weights from our best model\n",
    "        model = tf.keras.models.load_model(os.path.join(inference_folder, 'model_weights.keras'))\n",
    "        model.summary()\n",
    "\n",
    "        # perform a prediction\n",
    "        test_predictions_baseline = model.predict(x_test)\n",
    "        test_predictions_baseline = min_max.inverse_transform(test_predictions_baseline)\n",
    "        test_predictions_baseline = pd.DataFrame(test_predictions_baseline, columns=['Predicted_Price'])\n",
    "\n",
    "        # Combine the predicted values with dates from the test data\n",
    "        predicted_dates = pd.date_range(start=test_data.index[0], periods=len(test_predictions_baseline))\n",
    "        test_predictions_baseline['Date'] = predicted_dates\n",
    "        \n",
    "        # Reset the index for proper concatenation\n",
    "        test_data.reset_index(inplace=True)\n",
    "        \n",
    "        # Concatenate the test_data and predicted data\n",
    "        combined_data = pd.concat([test_data, test_predictions_baseline], ignore_index=True)\n",
    "        \n",
    "        # Plotting predictions\n",
    "        plt.figure(figsize=(14, 5))\n",
    "        plt.plot(combined_data['Date'], combined_data.Close, color='green', label='Simulated [' + STOCK_TICKER + '] price')\n",
    "        plt.plot(combined_data['Date'], combined_data['Predicted_Price'], color='red', label='Predicted [' + STOCK_TICKER + '] price')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Price [USD]')\n",
    "        plt.legend()\n",
    "        plt.title('Simulated vs Predicted Prices')\n",
    "        plt.savefig(os.path.join(inference_folder, STOCK_TICKER + '_future_comparison.png'))\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Error: Future data is empty.\")\n",
    "\n",
    "start_date = pd.to_datetime('2017-01-01')\n",
    "end_date = datetime.today()\n",
    "duration = end_date - start_date\n",
    "STOCK_VALIDATION_DATE = start_date + 0.8 * duration\n",
    "infer_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b787fe91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
