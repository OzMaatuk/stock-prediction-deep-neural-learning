{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "057ed8f6",
   "metadata": {},
   "source": [
    "## LSTM Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53a4edc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-02 22:50:43.604501: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "from src.stock_prediction_class import StockClass\n",
    "from src.stock_prediction_numpy import DataClass\n",
    "from src.stock_prediction_deep_learning import train_LSTM_network\n",
    "\n",
    "# Suppress TensorFlow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or '3' to suppress all messages\n",
    "\n",
    "# Suppress other warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"tensorflow\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adfc2ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import secrets\n",
    "# TOKEN = STOCK_TICKER + '_' + TODAY_RUN + '_' + secrets.token_hex(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce7e8a3a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker: GOOG\n",
      "Start Date: 2018-05-30\n",
      "Validation Date: 2021-05-30\n",
      "Test Run Folder: data/day/GOOG/\n"
     ]
    }
   ],
   "source": [
    "STOCK_TICKER = \"GOOG\"\n",
    "STOCK_START_DATE = pd.to_datetime(\"2018-05-30\")\n",
    "STOCK_VALIDATION_DATE = pd.to_datetime(\"2021-05-30\")\n",
    "STOCK_END_DATE = pd.to_datetime(\"2024-05-30\")\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 10\n",
    "TIME_STEPS = 1\n",
    "TODAY_RUN = datetime.today().strftime(\"%Y%m%d\")\n",
    "TOKEN = \"GOOG\"\n",
    "FOLDER_PREFIX = \"data/day/\"\n",
    "RUN_FOLDER = f\"{FOLDER_PREFIX}{TOKEN}/\"\n",
    "WORK_DIR = os.path.join(os.getcwd(), RUN_FOLDER)\n",
    "CSV_FILE = f\"{WORK_DIR}data.csv\"\n",
    "\n",
    "print('Ticker: ' + STOCK_TICKER)\n",
    "print('Start Date: ' + STOCK_START_DATE.strftime(\"%Y-%m-%d\"))\n",
    "print('Validation Date: ' + STOCK_VALIDATION_DATE.strftime(\"%Y-%m-%d\"))\n",
    "print('Test Run Folder: ' + RUN_FOLDER)\n",
    "\n",
    "PROJECT_FOLDER = os.path.join(os.getcwd(), RUN_FOLDER)\n",
    "if not os.path.exists(PROJECT_FOLDER):\n",
    "    os.makedirs(PROJECT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3068309",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_prediction = StockClass(STOCK_TICKER, \n",
    "                                   STOCK_START_DATE,\n",
    "                                   STOCK_END_DATE,\n",
    "                                   STOCK_VALIDATION_DATE, \n",
    "                                   PROJECT_FOLDER, \n",
    "                                   EPOCHS,\n",
    "                                   TIME_STEPS,\n",
    "                                   TOKEN,\n",
    "                                   BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa0cfbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: [0.5        0.29170237]\n",
      "max 1.0\n",
      "min 0.0\n",
      "Std dev: [0.28905723 0.23739201]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1510 into shape (755,1,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m\n\u001b[1;32m      2\u001b[0m stock_data \u001b[38;5;241m=\u001b[39m DataClass()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# (x_train, y_train), (x_test, y_test), (training_data, test_data) = data.download_transform_to_numpy(\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# stock.ticker, \u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# stock.time_steps, \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# stock.end_date,\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# stock.validation_date)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m (x_train, y_train), (x_test, y_test), (training_data, test_data) \u001b[38;5;241m=\u001b[39m \u001b[43mstock_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_csv_transform_to_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTIME_STEPS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCSV_FILE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSTOCK_VALIDATION_DATE\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/stock-prediction-deep-neural-learning/src/stock_prediction_numpy.py:34\u001b[0m, in \u001b[0;36mDataClass.load_csv_transform_to_numpy\u001b[0;34m(self, time_steps, csv_path, validation_date)\u001b[0m\n\u001b[1;32m     32\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv_path) \u001b[38;5;66;03m#, index_col=0)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# data = data.reset_index()\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_date\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/stock-prediction-deep-neural-learning/src/stock_prediction_numpy.py:57\u001b[0m, in \u001b[0;36mDataClass.transform_numpy\u001b[0;34m(self, data, time_steps, validation_date)\u001b[0m\n\u001b[1;32m     54\u001b[0m     y_train\u001b[38;5;241m.\u001b[39mappend(train_scaled[i, \u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     56\u001b[0m x_train, y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(x_train), np\u001b[38;5;241m.\u001b[39marray(y_train)\n\u001b[0;32m---> 57\u001b[0m x_train \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m total_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat((training_data, test_data), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     60\u001b[0m inputs \u001b[38;5;241m=\u001b[39m total_data[\u001b[38;5;28mlen\u001b[39m(total_data) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(test_data) \u001b[38;5;241m-\u001b[39m time_steps:]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py:285\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape\u001b[39m(a, newshape, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    202\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03m           [5, 6]])\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreshape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1510 into shape (755,1,1)"
     ]
    }
   ],
   "source": [
    "# Data loading\n",
    "stock_data = DataClass()\n",
    "# (x_train, y_train), (x_test, y_test), (training_data, test_data) = data.download_transform_to_numpy(\n",
    "    # stock.ticker, \n",
    "    # stock.time_steps, \n",
    "    # stock.project_folder,\n",
    "    # stock.start_date,\n",
    "    # stock.end_date,\n",
    "    # stock.validation_date)\n",
    "(x_train, y_train), (x_test, y_test), (training_data, test_data) = stock_data.load_csv_transform_to_numpy(TIME_STEPS, CSV_FILE, STOCK_VALIDATION_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489fe9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Deep Learning model\n",
    "train_LSTM_network(stock_data, stock_prediction, x_train, y_train, x_test, y_test, training_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e586ea",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc642506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_data(stock_data, start_date, end_date, latest_close_price, work_dir):\n",
    "    \n",
    "    x_test, y_test, test_data = stock_data.generate_future_data(TIME_STEPS, start_date, end_date, latest_close_price)\n",
    "\n",
    "    # Check if the future data is not empty\n",
    "    if x_test.shape[0] > 0:\n",
    "        # load the weights from our best model\n",
    "        model = tf.keras.models.load_model(os.path.join(work_dir, 'model_weights.keras'))\n",
    "        model.summary()\n",
    "\n",
    "        # perform a prediction\n",
    "        test_predictions_baseline = model.predict(x_test)\n",
    "        test_predictions_baseline = stock_data.min_max.inverse_transform(test_predictions_baseline)\n",
    "        test_predictions_baseline = pd.DataFrame(test_predictions_baseline, columns=['Predicted_Price'])\n",
    "\n",
    "        # Combine the predicted values with dates from the test data\n",
    "        predicted_dates = pd.date_range(start=test_data.index[0], periods=len(test_predictions_baseline))\n",
    "        test_predictions_baseline['Date'] = predicted_dates\n",
    "        \n",
    "        # Reset the index for proper concatenation\n",
    "        test_data.reset_index(inplace=True)\n",
    "        \n",
    "        # Concatenate the test_data and predicted data\n",
    "        combined_data = pd.concat([test_data, test_predictions_baseline], ignore_index=True)\n",
    "        \n",
    "        # Plotting predictions\n",
    "        plt.figure(figsize=(14, 5))\n",
    "        plt.plot(combined_data['Date'], combined_data.Close, color='green', label='Simulated [' + STOCK_TICKER + '] price')\n",
    "        plt.plot(combined_data['Date'], combined_data['Predicted_Price'], color='red', label='Predicted [' + STOCK_TICKER + '] price')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Price [USD]')\n",
    "        plt.legend()\n",
    "        plt.title('Simulated vs Predicted Prices')\n",
    "        plt.savefig(os.path.join(work_dir, 'future_comparison.png'))\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Error: Future data is empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b787fe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data = DataClass()\n",
    "\n",
    "data = pd.read_csv(CSV_FILE)\n",
    "\n",
    "latest_close_price = data['Close'].iloc[-1]\n",
    "latest_date = data['Date'].iloc[-1]\n",
    "\n",
    "print(f\"{latest_close_price}: latest_close_price\")\n",
    "print(f\"{latest_date}: latest_date\")\n",
    "\n",
    "start_date = pd.to_datetime(latest_date) + timedelta(1)\n",
    "# Specify the next X days\n",
    "X = 6\n",
    "end_date = pd.to_datetime(latest_date) + timedelta(TIME_STEPS * X)\n",
    "\n",
    "print(f\"{start_date}: start_date\")\n",
    "print(f\"{end_date}: end_date\")\n",
    "\n",
    "infer_data(stock_data, start_date, end_date, latest_close_price, WORK_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
