{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "057ed8f6",
   "metadata": {},
   "source": [
    "## LSTM Network - Prediction (model training)\n",
    "\n",
    "The example below will build the LSTM model on the FTSE 100 up to today (2024-01-03) and split the training/validation. Then the prediction module will look ahead 300 days and try to make a  prediction based on a random generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53a4edc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 22:50:12.500689: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2020-2024 Jordi Corbilla. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "import os\n",
    "# os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "import warnings\n",
    "import secrets\n",
    "import pandas as pd\n",
    "\n",
    "from src.stock_prediction_class import StockPrediction\n",
    "from src.stock_prediction_numpy import StockData\n",
    "from src.stock_prediction_deep_learning import train_LSTM_network\n",
    "\n",
    "# Suppress TensorFlow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or '3' to suppress all messages\n",
    "\n",
    "# Suppress other warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"tensorflow\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "# os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce7e8a3a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker: GOOG\n",
      "Start Date: 2020-05-01\n",
      "Validation Date: 2020-05-01\n",
      "Test Run Folder: GOOG_20240528_6a5c321a3b04ae3be5601f2ef386a571\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'Timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 32\u001b[0m\n\u001b[1;32m     22\u001b[0m stock_prediction \u001b[38;5;241m=\u001b[39m StockPrediction(STOCK_TICKER, \n\u001b[1;32m     23\u001b[0m                                    STOCK_START_DATE, \n\u001b[1;32m     24\u001b[0m                                    STOCK_VALIDATION_DATE, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m                                    TOKEN,\n\u001b[1;32m     30\u001b[0m                                    BATCH_SIZE)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Execute Deep Learning model\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[43mtrain_LSTM_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstock_prediction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/stock-prediction-deep-neural-learning/src/stock_prediction_deep_learning.py:34\u001b[0m, in \u001b[0;36mtrain_LSTM_network\u001b[0;34m(stock)\u001b[0m\n\u001b[1;32m     32\u001b[0m plotter \u001b[38;5;241m=\u001b[39m Plotter(\u001b[38;5;28;01mTrue\u001b[39;00m, stock\u001b[38;5;241m.\u001b[39mget_project_folder(), data\u001b[38;5;241m.\u001b[39mget_stock_short_name(), data\u001b[38;5;241m.\u001b[39mget_stock_currency(), stock\u001b[38;5;241m.\u001b[39mget_ticker())\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# (x_train, y_train), (x_test, y_test), (training_data, test_data) = data.download_transform_to_numpy(stock.get_time_steps(), stock.get_project_folder())\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m (x_train, y_train), (x_test, y_test), (training_data, test_data) \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_csv_transform_to_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_time_steps\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_project_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdownloaded_data_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_ticker\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m plotter\u001b[38;5;241m.\u001b[39mplot_histogram_data_split(training_data, test_data, stock\u001b[38;5;241m.\u001b[39mget_validation_date())\n\u001b[1;32m     37\u001b[0m lstm \u001b[38;5;241m=\u001b[39m LongShortTermMemory(stock\u001b[38;5;241m.\u001b[39mget_project_folder())\n",
      "File \u001b[0;32m/workspaces/stock-prediction-deep-neural-learning/src/stock_prediction_numpy.py:59\u001b[0m, in \u001b[0;36mStockData.load_csv_transform_to_numpy\u001b[0;34m(self, time_steps, csv_path)\u001b[0m\n\u001b[1;32m     57\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv_path)\n\u001b[1;32m     58\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_steps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/stock-prediction-deep-neural-learning/src/stock_prediction_numpy.py:62\u001b[0m, in \u001b[0;36mStockData.transform_numpy\u001b[0;34m(self, data, time_steps)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, time_steps):\n\u001b[0;32m---> 62\u001b[0m     training_data \u001b[38;5;241m=\u001b[39m data[\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_validation_date\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     63\u001b[0m     test_data \u001b[38;5;241m=\u001b[39m data[data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stock\u001b[38;5;241m.\u001b[39mget_validation_date()]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     64\u001b[0m     training_data \u001b[38;5;241m=\u001b[39m training_data\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:48\u001b[0m, in \u001b[0;36mOpsMixin.__lt__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__lt__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__lt__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py:6119\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6116\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   6117\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 6119\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/ops/array_ops.py:344\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 344\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    347\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/ops/array_ops.py:129\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m    127\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32mops.pyx:107\u001b[0m, in \u001b[0;36mpandas._libs.ops.scalar_compare\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'Timestamp'"
     ]
    }
   ],
   "source": [
    "STOCK_TICKER = \"GOOG\"\n",
    "STOCK_START_DATE = pd.to_datetime(\"2020-05-01\")\n",
    "STOCK_VALIDATION_DATE = pd.to_datetime(\"2021-05-01\")\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 10\n",
    "TIME_STEPS = 3\n",
    "TODAY_RUN = datetime.today().strftime(\"%Y%m%d\")\n",
    "# TOKEN = STOCK_TICKER + '_' + TODAY_RUN + '_' + secrets.token_hex(16)\n",
    "TOKEN = \"GOOG_20240528_6a5c321a3b04ae3be5601f2ef386a571\"\n",
    "FOLDER_PREFIX = \"data/\"\n",
    "RUN_FOLDER = f\"{FOLDER_PREFIX}{TOKEN}/\"\n",
    "print('Ticker: ' + STOCK_TICKER)\n",
    "print('Start Date: ' + STOCK_START_DATE.strftime(\"%Y-%m-%d\"))\n",
    "print('Validation Date: ' + STOCK_START_DATE.strftime(\"%Y-%m-%d\"))\n",
    "print('Test Run Folder: ' + RUN_FOLDER)\n",
    "# create project run folder\n",
    "PROJECT_FOLDER = os.path.join(os.getcwd(), RUN_FOLDER)\n",
    "if not os.path.exists(PROJECT_FOLDER):\n",
    "    os.makedirs(PROJECT_FOLDER)\n",
    "\n",
    "stock_prediction = StockPrediction(STOCK_TICKER, \n",
    "                                   STOCK_START_DATE, \n",
    "                                   STOCK_VALIDATION_DATE, \n",
    "                                   PROJECT_FOLDER, \n",
    "                                   EPOCHS,\n",
    "                                   TIME_STEPS,\n",
    "                                   TOKEN,\n",
    "                                   BATCH_SIZE)\n",
    "# Execute Deep Learning model\n",
    "train_LSTM_network(stock_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e586ea",
   "metadata": {},
   "source": [
    "## Infer the Future Data (Predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc642506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_data():\n",
    "    print(tf.version.VERSION)\n",
    "    inference_folder = os.path.join(os.getcwd(), RUN_FOLDER)\n",
    "    stock = StockPrediction(STOCK_TICKER, STOCK_START_DATE, STOCK_VALIDATION_DATE, inference_folder, EPOCHS, TIME_STEPS, TOKEN, BATCH_SIZE)\n",
    "\n",
    "    data = StockData(stock)\n",
    "\n",
    "    # (x_train, y_train), (x_test, y_test), (training_data, test_data) = data.download_transform_to_numpy(TIME_STEPS, inference_folder)\n",
    "    csv_file = \"data/GOOG_20240528_6a5c321a3b04ae3be5601f2ef386a571/downloaded_data_GOOG.csv\"\n",
    "    (x_train, y_train), (x_test, y_test), (training_data, test_data) = data.load_csv_transform_to_numpy(TIME_STEPS, csv_file)\n",
    "    min_max = data.get_min_max()\n",
    "\n",
    "    # load future data\n",
    "    print('Latest Stock Price')\n",
    "    latest_close_price = test_data.Close.iloc[-1]\n",
    "    latest_date = test_data[-1:]['Close'].idxmin()\n",
    "    print(latest_close_price)\n",
    "    print('Latest Date')\n",
    "    print(latest_date)\n",
    "\n",
    "    tomorrow_date = latest_date + timedelta(1)\n",
    "    # Specify the next 300 days\n",
    "    next_year = latest_date + timedelta(TIME_STEPS * 100)\n",
    "\n",
    "    print('Future Date')\n",
    "    print(tomorrow_date)\n",
    "\n",
    "    print('Future Timespan Date')\n",
    "    print(next_year)\n",
    "\n",
    "    x_test, y_test, test_data = data.generate_future_data(TIME_STEPS, min_max, tomorrow_date, next_year, latest_close_price)\n",
    "\n",
    "    # Check if the future data is not empty\n",
    "    if x_test.shape[0] > 0:\n",
    "        # load the weights from our best model\n",
    "        model = tf.keras.models.load_model(os.path.join(inference_folder, 'model_weights.keras'))\n",
    "        model.summary()\n",
    "\n",
    "        # perform a prediction\n",
    "        test_predictions_baseline = model.predict(x_test)\n",
    "        test_predictions_baseline = min_max.inverse_transform(test_predictions_baseline)\n",
    "        test_predictions_baseline = pd.DataFrame(test_predictions_baseline, columns=['Predicted_Price'])\n",
    "\n",
    "        # Combine the predicted values with dates from the test data\n",
    "        predicted_dates = pd.date_range(start=test_data.index[0], periods=len(test_predictions_baseline))\n",
    "        test_predictions_baseline['Date'] = predicted_dates\n",
    "        \n",
    "        # Reset the index for proper concatenation\n",
    "        test_data.reset_index(inplace=True)\n",
    "        \n",
    "        # Concatenate the test_data and predicted data\n",
    "        combined_data = pd.concat([test_data, test_predictions_baseline], ignore_index=True)\n",
    "        \n",
    "        # Plotting predictions\n",
    "        plt.figure(figsize=(14, 5))\n",
    "        plt.plot(combined_data['Date'], combined_data.Close, color='green', label='Simulated [' + STOCK_TICKER + '] price')\n",
    "        plt.plot(combined_data['Date'], combined_data['Predicted_Price'], color='red', label='Predicted [' + STOCK_TICKER + '] price')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Price [USD]')\n",
    "        plt.legend()\n",
    "        plt.title('Simulated vs Predicted Prices')\n",
    "        plt.savefig(os.path.join(inference_folder, STOCK_TICKER + '_future_comparison.png'))\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Error: Future data is empty.\")\n",
    "\n",
    "start_date = pd.to_datetime('2017-01-01')\n",
    "end_date = datetime.today()\n",
    "duration = end_date - start_date\n",
    "STOCK_VALIDATION_DATE = start_date + 0.8 * duration\n",
    "infer_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b787fe91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
